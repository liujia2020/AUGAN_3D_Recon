"""
AUGAN 3D è®­ç»ƒä¸»å…¥å£è„šæœ¬ (V8.1 - ä¿®å¤æ¢¯åº¦æŠ¥é”™ç‰ˆ)
ä¿®å¤äº† save_nii æ—¶å› æœª detach å¯¼è‡´çš„ RuntimeErrorã€‚
"""
import time
import os
import torch
import numpy as np
import random
from tqdm import tqdm
from torch.utils.tensorboard import SummaryWriter
import matplotlib
matplotlib.use('Agg') 
import matplotlib.pyplot as plt
import nibabel as nib 

from options.train_options import TrainOptions
from data import create_dataset
from models import create_model

# ==============================================================================
# [è¾…åŠ©å‡½æ•°]
# ==============================================================================

def set_seed(seed):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True

def get_pixel_stats(tensor):
    return {
        'min': tensor.min().item(),
        'max': tensor.max().item(),
        'mean': tensor.mean().item()
    }

def print_training_summary(opt, dataset, model):
    """æ‰“å°è¯¦ç»†çš„è®­ç»ƒé…ç½®æ‘˜è¦"""
    device = torch.device('cuda:{}'.format(opt.gpu_ids[0])) if opt.gpu_ids else torch.device('cpu')
    visual_aspect = opt.spacing_z / opt.spacing_x
    
    print("\n" + "="*80)
    print(f"{'ğŸš€ AUGAN TRAINING CONFIGURATION':^80}")
    print("="*80)
    print(f"  - Device:        {device}")
    print(f"  - Data Root:     {opt.dataroot}")
    print(f"  - Dataset Size:  {len(dataset)} volumes")
    print(f"  - Batch Size:    {opt.batch_size}")
    print(f"  - Physics:       Z_spacing={opt.spacing_z}mm, X_spacing={opt.spacing_x}mm")
    print(f"  - Visual Aspect: {visual_aspect:.4f} (Image will be vertically compressed)")
    print(f"  - Model:         G={opt.netG}, D={opt.netD}")
    print(f"  - LR Config:     G={opt.lr}, D={opt.lr * opt.lr_d_ratio}")
    print(f"  - L2 Weight:     {opt.lambda_L2}")
    print("="*80 + "\n")

def print_epoch_report(epoch, total_epochs, epoch_time, losses_avg, lr_G, lr_D):
    """æ‰“å° Epoch ç»“æ¡ˆæŠ¥å‘Š"""
    print('-' * 80)
    print(f'END OF EPOCH {epoch} / {total_epochs} \t Time Taken: {epoch_time:.0f} sec')
    print(f'  Learning Rates: \t G_lr = {lr_G:.7f} | D_lr = {lr_D:.7f}')
    
    loss_G_total = losses_avg.get('G_GAN', 0) + losses_avg.get('G_L2', 0)
    loss_D_total = (losses_avg.get('D_Real', 0) + losses_avg.get('D_Fake', 0)) * 0.5
    
    print('  Average Losses:')
    print(f'    Generator (G): \t Total â‰ˆ {loss_G_total:.4f}')
    print(f'      â”œâ”€ G_Adversarial: \t {losses_avg.get("G_GAN", 0):.4f}')
    print(f'      â””â”€ G_Pixelwise (L2): \t {losses_avg.get("G_L2", 0):.4f}')
    print(f'    Discriminator (D): \t Total â‰ˆ {loss_D_total:.4f}')
    print(f'      â”œâ”€ D_Real_Loss: \t {losses_avg.get("D_Real", 0):.4f}')
    print(f'      â””â”€ D_Fake_Loss: \t {losses_avg.get("D_Fake", 0):.4f}')
    print('-' * 80 + '\n')

def save_epoch_visuals(model, epoch, save_dir, writer, opt, save_nii=False):
    """
    ä¿å­˜å¯è§†åŒ–ç»“æœï¼š
    1. PNG å›¾ç‰‡ (ç‰©ç†æ¯”ä¾‹çŸ«æ­£ï¼Œæ¨ªå‘çŸ©å½¢)
    2. NIfTI æ–‡ä»¶ (å¸¦ç‰©ç†å¤´ä¿¡æ¯)
    """
    visual_aspect = opt.spacing_z / opt.spacing_x
    
    # 1. æå–æ•°æ®å¹¶ç”»å›¾ (ä½¿ç”¨ no_grad ä¸Šä¸‹æ–‡ï¼Œè‡ªåŠ¨å¤„ç†æ¢¯åº¦)
    with torch.no_grad():
        # å– Batch ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ Y è½´ä¸­é—´åˆ‡ç‰‡
        w_idx = model.real_lq.shape[4] // 2
        
        img_lq = model.real_lq[0, 0, :, :, w_idx].cpu().numpy()
        img_fake = model.fake_hq[0, 0, :, :, w_idx].cpu().numpy()
        img_real = model.real_hq[0, 0, :, :, w_idx].cpu().numpy()
        
        st_lq = get_pixel_stats(model.real_lq)
        st_fake = get_pixel_stats(model.fake_hq)
        st_real = get_pixel_stats(model.real_hq)

    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    t_lq = f"Input (LQ)\nRange:[{st_lq['min']:.2f}, {st_lq['max']:.2f}]"
    t_fake = f"Generated (Fake)\nRange:[{st_fake['min']:.2f}, {st_fake['max']:.2f}]"
    t_real = f"Ground Truth (HQ)\nRange:[{st_real['min']:.2f}, {st_real['max']:.2f}]"
    
    titles = [t_lq, t_fake, t_real]
    images = [img_lq, img_fake, img_real]
    
    for ax, img, title in zip(axes, images, titles):
        # ç‰©ç†æ¯”ä¾‹çŸ«æ­£
        im = ax.imshow(img, cmap='gray', vmin=-1, vmax=1, aspect=visual_aspect)
        ax.set_title(title, fontsize=10)
        ax.set_xlabel("Lateral (X)")
        ax.set_ylabel("Depth (Z)")
        ax.axis('on')
        
    plt.tight_layout()
    img_filename = f"epoch_{epoch:03d}.png"
    img_path = os.path.join(save_dir, img_filename)
    plt.savefig(img_path)
    plt.close(fig)
    
    writer.add_figure('Visual/Epoch_Compare', fig, global_step=epoch)
    print(f"  ğŸ–¼ï¸  Epoch {epoch} Visual Saved: {img_filename}")

    # 2. ä¿å­˜ NIfTI (ç‹¬ç«‹æ­¥éª¤)
    if save_nii:
        # [!!] å…³é”®ä¿®å¤: å¿…é¡»å…ˆ .detach() å† .cpu().numpy()
        # è¿˜åŸé¡ºåº: (1, 1, D, H, W) -> squeeze -> (D, H, W) -> permute -> (H, W, D)å³(X, Y, Z)
        vol_fake = model.fake_hq[0, 0].detach().cpu().numpy().transpose(1, 2, 0)
        
        # å†™å…¥ç‰©ç†é—´è·
        affine = np.diag([opt.spacing_x, opt.spacing_x, opt.spacing_z, 1.0])
        nii_fake = nib.Nifti1Image(vol_fake, affine)
        
        nii_filename = f"epoch_{epoch:03d}_fake.nii.gz"
        nii_path = os.path.join(save_dir, nii_filename)
        nib.save(nii_fake, nii_path)
        print(f"  ğŸ“¦ NIfTI Saved: {nii_filename}")

# ==============================================================================
# [ä¸»ç¨‹åº]
# ==============================================================================

if __name__ == '__main__':
    # 1. è§£æå‚æ•°
    opt_driver = TrainOptions() 
    opt = opt_driver.parse()    
    set_seed(42)
    
    # 2. å‡†å¤‡ç›®å½•
    log_dir = os.path.join(opt.checkpoints_dir, opt.name, 'logs')
    img_save_dir = os.path.join(opt.checkpoints_dir, opt.name, 'web_images')
    os.makedirs(log_dir, exist_ok=True)
    os.makedirs(img_save_dir, exist_ok=True)
    
    writer = SummaryWriter(log_dir=log_dir)

    # 3. åŠ è½½æ•°æ®ä¸æ¨¡å‹
    dataset = create_dataset(opt)
    model = create_model(opt)
    model.setup(opt)
    
    print("----------------------------------------------------------------")
    opt_driver.print_options(opt) 
    print_training_summary(opt, dataset, model)
    
    # 4. è®­ç»ƒå¾ªç¯
    total_iters = 0                
    total_epochs = opt.n_epochs + opt.n_epochs_decay
    
    # å¼ºåˆ¶åˆå§‹é‡‡æ · (Step 0)
    print("ğŸ“¸ Saving initial sample (Step 0 check)...")
    init_batch = next(iter(dataset))
    model.set_input(init_batch)
    model.forward() 
    # è¿™é‡Œçš„ save_nii=True ä¼šè§¦å‘åˆšæ‰ä¿®å¤çš„ä»£ç 
    save_epoch_visuals(model, 0, img_save_dir, writer, opt, save_nii=True)
    
    for epoch in range(opt.epoch_count, total_epochs + 1):
        epoch_start_time = time.time()
        epoch_losses = {'G_GAN': 0.0, 'G_L2': 0.0, 'D_Real': 0.0, 'D_Fake': 0.0}
        epoch_iter_count = 0
        
        print(f"\nStart Epoch {epoch} / {total_epochs}")
        progress_bar = tqdm(dataset, desc=f"Epoch {epoch}", unit="batch")

        for i, data in enumerate(progress_bar):
            total_iters += opt.batch_size
            epoch_iter_count += 1
            
            model.set_input(data)         
            model.optimize_parameters()   
            
            current_losses = model.get_current_losses()
            for k in epoch_losses.keys():
                epoch_losses[k] += current_losses.get(k, 0.0)

            if total_iters % opt.print_freq == 0:    
                progress_bar.set_postfix(G_L2=f"{current_losses['G_L2']:.3f}")
                for k, v in current_losses.items():
                    writer.add_scalar(f'Loss_Step/{k}', v, total_iters)

        # --- Epoch End ---
        avg_losses = {k: v / epoch_iter_count for k, v in epoch_losses.items()}
        for k, v in avg_losses.items():
            writer.add_scalar(f'Loss_Epoch/{k}', v, epoch)
            
        lr_G = model.optimizers[0].param_groups[0]['lr']
        lr_D = model.optimizers[1].param_groups[0]['lr']
        print_epoch_report(epoch, total_epochs, time.time() - epoch_start_time, avg_losses, lr_G, lr_D)
        
        # æ¯ä¸ª Epoch å¿…ä¿å­˜å›¾å’Œ NIfTI
        save_epoch_visuals(model, epoch, img_save_dir, writer, opt, save_nii=True)
        
        if epoch % opt.save_epoch_freq == 0:
            print(f'ğŸ’¾ Saving checkpoints at epoch {epoch}')
            model.save_networks('latest')
            model.save_networks(epoch)

        model.update_learning_rate() 
        
    writer.close()
    print("ğŸ‰ Training Finished!")